{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJhrhcYn0e_Q",
        "outputId": "76d20a4c-6675-4d6c-f32f-552ec2873996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wEDRLRs3aLK",
        "outputId": "164786dd-bdff-48b3-a039-81970985fa45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
            "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.2.0 (from tensorflow)\n",
            "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Collecting namex (from keras>=3.2.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.2.0->tensorflow)\n",
            "  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.4.1 ml-dtypes-0.4.0 namex-0.0.8 optree-0.12.1 tensorboard-2.17.0 tensorflow-2.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario de emociones\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "n1 = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
        "n2 = to_categorical(list(range(len(n1))))\n",
        "emociones_type1 = {n1[i]:n2[i] for i in range(len(n1))}\n",
        "emociones_type2 = {str(j):i for i,j in emociones_type1.items()}"
      ],
      "metadata": {
        "id": "321jF6FkGlCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBHJdwObndv8"
      },
      "outputs": [],
      "source": [
        "# Cargar los datos procesados\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = np.load('/content/gdrive/MyDrive/kaggle_faciales/X_tensor.npy')\n",
        "Y = np.load('/content/gdrive/MyDrive/kaggle_faciales/Y_tensor.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiFDCTPn1MzG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = X.reshape(-1, 70, 70, 1)\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "X_test, X_val, Y_test, Y_val = train_test_split(X_temp, Y_temp, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "fxQy3Ay1afbj",
        "outputId": "f5a03374-32d9-4708-88f3-c7c5272a33eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Ver ejemplo\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "ind = random.randint(0, len(X_train)-1)\n",
        "\n",
        "X_original = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(X_original[ind], cmap='gray')\n",
        "ax.axis('off')\n",
        "emotion_label = emociones_type2[str(Y_train[ind])]\n",
        "ax.set_title(emotion_label, fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvOOT9tb44gy",
        "outputId": "6cde8eac-a234-4c01-aed1-a928ee3c5204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 33ms/step - accuracy: 0.2335 - loss: 1.8368 - val_accuracy: 0.2597 - val_loss: 1.7802\n",
            "Epoch 2/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.2575 - loss: 1.7876 - val_accuracy: 0.2648 - val_loss: 1.7407\n",
            "Epoch 3/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.2647 - loss: 1.7604 - val_accuracy: 0.2804 - val_loss: 1.7179\n",
            "Epoch 4/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.2726 - loss: 1.7424 - val_accuracy: 0.3023 - val_loss: 1.6792\n",
            "Epoch 5/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 33ms/step - accuracy: 0.2873 - loss: 1.7145 - val_accuracy: 0.3325 - val_loss: 1.6552\n",
            "Epoch 6/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.3089 - loss: 1.6813 - val_accuracy: 0.4140 - val_loss: 1.5138\n",
            "Epoch 7/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.3495 - loss: 1.6173 - val_accuracy: 0.4283 - val_loss: 1.4603\n",
            "Epoch 8/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.3709 - loss: 1.5853 - val_accuracy: 0.4457 - val_loss: 1.4086\n",
            "Epoch 9/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.3863 - loss: 1.5477 - val_accuracy: 0.4597 - val_loss: 1.3958\n",
            "Epoch 10/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.3999 - loss: 1.5189 - val_accuracy: 0.4672 - val_loss: 1.3568\n",
            "Epoch 11/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4075 - loss: 1.5090 - val_accuracy: 0.4801 - val_loss: 1.3423\n",
            "Epoch 12/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4143 - loss: 1.4983 - val_accuracy: 0.4861 - val_loss: 1.3435\n",
            "Epoch 13/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4296 - loss: 1.4669 - val_accuracy: 0.4832 - val_loss: 1.3344\n",
            "Epoch 14/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4252 - loss: 1.4806 - val_accuracy: 0.4960 - val_loss: 1.3138\n",
            "Epoch 15/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4251 - loss: 1.4608 - val_accuracy: 0.4996 - val_loss: 1.2986\n",
            "Epoch 16/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4336 - loss: 1.4484 - val_accuracy: 0.5076 - val_loss: 1.2909\n",
            "Epoch 17/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.4392 - loss: 1.4363 - val_accuracy: 0.5061 - val_loss: 1.2942\n",
            "Epoch 18/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4465 - loss: 1.4286 - val_accuracy: 0.4997 - val_loss: 1.3054\n",
            "Epoch 19/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4412 - loss: 1.4273 - val_accuracy: 0.5053 - val_loss: 1.2874\n",
            "Epoch 20/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4492 - loss: 1.4150 - val_accuracy: 0.5156 - val_loss: 1.2649\n",
            "Epoch 21/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4574 - loss: 1.3963 - val_accuracy: 0.5080 - val_loss: 1.2748\n",
            "Epoch 22/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4540 - loss: 1.4038 - val_accuracy: 0.5243 - val_loss: 1.2491\n",
            "Epoch 23/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4513 - loss: 1.4021 - val_accuracy: 0.5105 - val_loss: 1.2647\n",
            "Epoch 24/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4644 - loss: 1.3875 - val_accuracy: 0.5155 - val_loss: 1.2564\n",
            "Epoch 25/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4597 - loss: 1.3992 - val_accuracy: 0.5234 - val_loss: 1.2507\n",
            "Epoch 26/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4699 - loss: 1.3746 - val_accuracy: 0.5204 - val_loss: 1.2466\n",
            "Epoch 27/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4669 - loss: 1.3794 - val_accuracy: 0.5271 - val_loss: 1.2338\n",
            "Epoch 28/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4742 - loss: 1.3666 - val_accuracy: 0.5134 - val_loss: 1.2681\n",
            "Epoch 29/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4765 - loss: 1.3620 - val_accuracy: 0.5271 - val_loss: 1.2386\n",
            "Epoch 30/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4725 - loss: 1.3710 - val_accuracy: 0.5300 - val_loss: 1.2484\n",
            "Epoch 31/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4704 - loss: 1.3667 - val_accuracy: 0.5282 - val_loss: 1.2299\n",
            "Epoch 32/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4818 - loss: 1.3635 - val_accuracy: 0.5345 - val_loss: 1.2256\n",
            "Epoch 33/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4782 - loss: 1.3645 - val_accuracy: 0.5294 - val_loss: 1.2368\n",
            "Epoch 34/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4742 - loss: 1.3559 - val_accuracy: 0.5161 - val_loss: 1.2410\n",
            "Epoch 35/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4828 - loss: 1.3503 - val_accuracy: 0.5242 - val_loss: 1.2365\n",
            "Epoch 36/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4830 - loss: 1.3544 - val_accuracy: 0.5305 - val_loss: 1.2196\n",
            "Epoch 37/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4819 - loss: 1.3454 - val_accuracy: 0.5275 - val_loss: 1.2352\n",
            "Epoch 38/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4807 - loss: 1.3525 - val_accuracy: 0.5290 - val_loss: 1.2167\n",
            "Epoch 39/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4833 - loss: 1.3445 - val_accuracy: 0.5306 - val_loss: 1.2149\n",
            "Epoch 40/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4915 - loss: 1.3315 - val_accuracy: 0.5282 - val_loss: 1.2156\n",
            "Epoch 41/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4879 - loss: 1.3305 - val_accuracy: 0.5342 - val_loss: 1.2170\n",
            "Epoch 42/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4892 - loss: 1.3389 - val_accuracy: 0.5366 - val_loss: 1.2133\n",
            "Epoch 43/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4894 - loss: 1.3318 - val_accuracy: 0.5304 - val_loss: 1.2199\n",
            "Epoch 44/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4888 - loss: 1.3419 - val_accuracy: 0.5428 - val_loss: 1.1957\n",
            "Epoch 45/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4943 - loss: 1.3259 - val_accuracy: 0.5377 - val_loss: 1.2131\n",
            "Epoch 46/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4915 - loss: 1.3322 - val_accuracy: 0.5427 - val_loss: 1.1938\n",
            "Epoch 47/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.4928 - loss: 1.3351 - val_accuracy: 0.5346 - val_loss: 1.2091\n",
            "Epoch 48/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4943 - loss: 1.3159 - val_accuracy: 0.5284 - val_loss: 1.2280\n",
            "Epoch 49/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4972 - loss: 1.3242 - val_accuracy: 0.5394 - val_loss: 1.2073\n",
            "Epoch 50/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.4897 - loss: 1.3319 - val_accuracy: 0.5397 - val_loss: 1.1980\n"
          ]
        }
      ],
      "source": [
        "# Arquitectura del modelo\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=30,width_shift_range=0.1,\n",
        "                             height_shift_range=0.1,zoom_range=0.1)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(70, 70, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo, primeras épocas\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "history = model.fit(datagen.flow(X_train, Y_train, batch_size=32), epochs=50, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "id": "UhY1KU-fY01Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/MyDrive/kaggle_faciales/modelo1_50ep.keras')"
      ],
      "metadata": {
        "id": "zVn0nvvsVv4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/gdrive/MyDrive/kaggle_faciales/modelo1_50ep.keras')"
      ],
      "metadata": {
        "id": "oOAgqIDuV2is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segundo entrenamiento del modelo, añadiendo más epocas\n",
        "\n",
        "history = model.fit(datagen.flow(X_train, Y_train, batch_size=32), epochs=70,\n",
        "                    initial_epoch = 50, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bAO2OdAVnrm",
        "outputId": "0b87700f-6c4c-4cba-e1b7-3cdbd6ca884c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5173 - loss: 1.2762 - val_accuracy: 0.5538 - val_loss: 1.1583\n",
            "Epoch 52/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.5204 - loss: 1.2660 - val_accuracy: 0.5537 - val_loss: 1.1712\n",
            "Epoch 53/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.5098 - loss: 1.2729 - val_accuracy: 0.5488 - val_loss: 1.1735\n",
            "Epoch 54/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.5254 - loss: 1.2688 - val_accuracy: 0.5559 - val_loss: 1.1638\n",
            "Epoch 55/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5199 - loss: 1.2646 - val_accuracy: 0.5664 - val_loss: 1.1456\n",
            "Epoch 56/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5188 - loss: 1.2812 - val_accuracy: 0.5699 - val_loss: 1.1512\n",
            "Epoch 57/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5199 - loss: 1.2681 - val_accuracy: 0.5544 - val_loss: 1.1567\n",
            "Epoch 58/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5168 - loss: 1.2698 - val_accuracy: 0.5539 - val_loss: 1.1648\n",
            "Epoch 59/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5179 - loss: 1.2645 - val_accuracy: 0.5583 - val_loss: 1.1538\n",
            "Epoch 60/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5211 - loss: 1.2634 - val_accuracy: 0.5532 - val_loss: 1.1651\n",
            "Epoch 61/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5257 - loss: 1.2523 - val_accuracy: 0.5554 - val_loss: 1.1595\n",
            "Epoch 62/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.5199 - loss: 1.2601 - val_accuracy: 0.5447 - val_loss: 1.1728\n",
            "Epoch 63/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5236 - loss: 1.2545 - val_accuracy: 0.5632 - val_loss: 1.1404\n",
            "Epoch 64/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.5242 - loss: 1.2625 - val_accuracy: 0.5566 - val_loss: 1.1622\n",
            "Epoch 65/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.5234 - loss: 1.2629 - val_accuracy: 0.5573 - val_loss: 1.1454\n",
            "Epoch 66/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5212 - loss: 1.2673 - val_accuracy: 0.5558 - val_loss: 1.1611\n",
            "Epoch 67/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5251 - loss: 1.2553 - val_accuracy: 0.5547 - val_loss: 1.1621\n",
            "Epoch 68/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.5162 - loss: 1.2689 - val_accuracy: 0.5653 - val_loss: 1.1513\n",
            "Epoch 69/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.5224 - loss: 1.2548 - val_accuracy: 0.5530 - val_loss: 1.1574\n",
            "Epoch 70/70\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.5276 - loss: 1.2563 - val_accuracy: 0.5476 - val_loss: 1.1782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/MyDrive/kaggle_faciales/modelo1_70ep.keras')"
      ],
      "metadata": {
        "id": "fO9Vwv5eXksi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ampliación de la arquitecura del modelo y cambios en el datagen\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "new_datagen = ImageDataGenerator(rotation_range=45,width_shift_range=0.25,\n",
        "                             height_shift_range=0.25,zoom_range=0.25,\n",
        "                             horizontal_flip=True,vertical_flip=True,\n",
        "                             shear_range=0.2,brightness_range=[0.8, 1.2],\n",
        "                             channel_shift_range=30.0)\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(70, 70, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VyxinRXX1uQ",
        "outputId": "3405396d-7737-49a5-90d0-93c709a6a293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el nuevo modelo\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "history = model.fit(datagen.flow(X_train, Y_train, batch_size=32), epochs=90,\n",
        "                    initial_epoch = 55, validation_data=(X_test, Y_test))\n",
        "\n",
        "model.save('/content/gdrive/MyDrive/kaggle_faciales/modelo2_90ep.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow9QIHmSsO0N",
        "outputId": "33ee4d2c-c3d5-4700-8db8-2934d7dac3ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5753 - loss: 1.1344 - val_accuracy: 0.6069 - val_loss: 1.0545\n",
            "Epoch 57/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5762 - loss: 1.1287 - val_accuracy: 0.5684 - val_loss: 1.1260\n",
            "Epoch 58/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5730 - loss: 1.1310 - val_accuracy: 0.5803 - val_loss: 1.0878\n",
            "Epoch 59/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5761 - loss: 1.1228 - val_accuracy: 0.5606 - val_loss: 1.1607\n",
            "Epoch 60/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5763 - loss: 1.1274 - val_accuracy: 0.6057 - val_loss: 1.0543\n",
            "Epoch 61/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5815 - loss: 1.1160 - val_accuracy: 0.5986 - val_loss: 1.0650\n",
            "Epoch 62/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5829 - loss: 1.1123 - val_accuracy: 0.6074 - val_loss: 1.0441\n",
            "Epoch 63/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5799 - loss: 1.1151 - val_accuracy: 0.6041 - val_loss: 1.0465\n",
            "Epoch 64/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5850 - loss: 1.1111 - val_accuracy: 0.6014 - val_loss: 1.0612\n",
            "Epoch 65/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5803 - loss: 1.1161 - val_accuracy: 0.5848 - val_loss: 1.1108\n",
            "Epoch 66/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5803 - loss: 1.1105 - val_accuracy: 0.5900 - val_loss: 1.0753\n",
            "Epoch 67/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5829 - loss: 1.1085 - val_accuracy: 0.6010 - val_loss: 1.0626\n",
            "Epoch 68/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5896 - loss: 1.1033 - val_accuracy: 0.6009 - val_loss: 1.0633\n",
            "Epoch 69/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5800 - loss: 1.1090 - val_accuracy: 0.6171 - val_loss: 1.0188\n",
            "Epoch 70/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5840 - loss: 1.1076 - val_accuracy: 0.6024 - val_loss: 1.0583\n",
            "Epoch 71/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5851 - loss: 1.1029 - val_accuracy: 0.5969 - val_loss: 1.0699\n",
            "Epoch 72/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5892 - loss: 1.1095 - val_accuracy: 0.6028 - val_loss: 1.0444\n",
            "Epoch 73/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5855 - loss: 1.1092 - val_accuracy: 0.6120 - val_loss: 1.0252\n",
            "Epoch 74/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5789 - loss: 1.1076 - val_accuracy: 0.5947 - val_loss: 1.0897\n",
            "Epoch 75/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.5850 - loss: 1.1051 - val_accuracy: 0.6116 - val_loss: 1.0309\n",
            "Epoch 76/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5845 - loss: 1.0916 - val_accuracy: 0.5920 - val_loss: 1.0904\n",
            "Epoch 77/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5857 - loss: 1.1034 - val_accuracy: 0.6062 - val_loss: 1.0418\n",
            "Epoch 78/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5939 - loss: 1.0906 - val_accuracy: 0.6019 - val_loss: 1.0551\n",
            "Epoch 79/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5943 - loss: 1.0858 - val_accuracy: 0.6092 - val_loss: 1.0470\n",
            "Epoch 80/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5907 - loss: 1.0894 - val_accuracy: 0.6012 - val_loss: 1.0454\n",
            "Epoch 81/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5899 - loss: 1.0892 - val_accuracy: 0.6035 - val_loss: 1.0320\n",
            "Epoch 82/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5844 - loss: 1.0918 - val_accuracy: 0.6072 - val_loss: 1.0248\n",
            "Epoch 83/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5890 - loss: 1.0942 - val_accuracy: 0.5773 - val_loss: 1.1072\n",
            "Epoch 84/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5927 - loss: 1.0846 - val_accuracy: 0.6161 - val_loss: 1.0118\n",
            "Epoch 85/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5968 - loss: 1.0877 - val_accuracy: 0.6101 - val_loss: 1.0528\n",
            "Epoch 86/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5912 - loss: 1.0891 - val_accuracy: 0.6032 - val_loss: 1.0362\n",
            "Epoch 87/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5904 - loss: 1.0843 - val_accuracy: 0.6210 - val_loss: 1.0119\n",
            "Epoch 88/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5899 - loss: 1.0888 - val_accuracy: 0.6148 - val_loss: 1.0354\n",
            "Epoch 89/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5965 - loss: 1.0680 - val_accuracy: 0.6051 - val_loss: 1.0384\n",
            "Epoch 90/90\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.5950 - loss: 1.0696 - val_accuracy: 0.5942 - val_loss: 1.0849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/gdrive/MyDrive/kaggle_faciales/modelo2_90ep.keras')"
      ],
      "metadata": {
        "id": "8LwMrlMHs8BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_val, Y_val, verbose=1)\n",
        "\n",
        "print(f\"Pérdida en el conjunto de validación: {loss}\")\n",
        "print(f\"Precisión en el conjunto de validación: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lngcHo82xMew",
        "outputId": "f5f1181d-e69d-434b-c2cb-19bf78c7258f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.5758 - loss: 1.1709\n",
            "Pérdida en el conjunto de validación: 1.1367110013961792\n",
            "Precisión en el conjunto de validación: 0.579556405544281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H72jCiCob_ZA"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}